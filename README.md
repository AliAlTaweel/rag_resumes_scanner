# ðŸ“„ Resume Screener

A cloud-powered, RAG-based resume screening tool built with **LangChain**, **Pinecone**, and **HuggingFace**. Drop PDF resumes into a folder, ask natural-language questions, and get instant AI-generated answers via a Gradio web UI.

---

## Architecture

```
resume_screener/
â”œâ”€â”€ main.py                  # Entry point â€” bootstraps pipeline & launches UI
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ loaders/
â”‚   â”‚   â””â”€â”€ document_loader.py   # PDF loading & text splitting
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â””â”€â”€ embedding_model.py   # HuggingFace sentence-transformer wrapper
â”‚   â”œâ”€â”€ retriever/
â”‚   â”‚   â””â”€â”€ vector_store.py      # Pinecone vector store: create & load
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ llm.py               # LLM factory (HuggingFace Inference API)
â”‚   â”‚   â””â”€â”€ chain.py             # RAG chain construction & query execution
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ __init__.py          # Logging setup & HuggingFace auth
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py              # Shared pytest fixtures
â”‚   â”œâ”€â”€ test_loader.py           # Tests for document loading & splitting
â”‚   â”œâ”€â”€ test_embeddings.py       # Tests for the embedding model
â”‚   â”œâ”€â”€ test_retriever.py        # Tests for vector store creation & loading
â”‚   â””â”€â”€ test_rag_chain.py        # Tests for RAG chain & ask_question
â”œâ”€â”€ notebooks/                   # notebooks
â”‚   â””â”€â”€ rag_resumes_scanner.ipynb
â”œâ”€â”€ resumes/                     # Place PDF resumes here (git-ignored)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ Makefile
â””â”€â”€ .env.example
```

---

## Quick Start

### 1. Clone & set up environment

```bash
git clone <repo-url>
cd resume_screener
python -m venv .venv && source .venv/bin/activate
make install
```

### 2. Configure secrets

```bash
cp .env.example .env
# Edit .env with your real API keys
```

| Variable | Description |
|---|---|
| `HUGGINGFACEHUB_API_TOKEN` | HuggingFace API token (from [hf.co/settings/tokens](https://huggingface.co/settings/tokens)) |
| `PINECONE_API_KEY` | Pinecone API key (from [app.pinecone.io](https://app.pinecone.io)) |
| `PINECONE_INDEX_NAME` | Name for the Pinecone index (default: `resumes-index`) |
| `RESUMES_DIR` | Path to the folder containing PDF resumes (default: `./resumes`) |

### 3. Add resumes

```bash
cp /path/to/*.pdf resumes/
```

### 4. Launch the app

```bash
make run
# â†’ http://127.0.0.1:7860
```

---

## Usage

Open the Gradio UI and type questions such as:

- *"Which candidate has the most Python experience?"*
- *"Who has worked with machine learning frameworks?"*
- *"List all candidates with a Masters degree."*

---

## Development

### Install dev dependencies

```bash
make dev-install
```

### Run tests

```bash
make test            # all tests
make test-loader     # loader tests only
make test-embeddings # embedding tests only
make test-retriever  # retriever tests only
make test-rag        # RAG chain tests only
make test-cov        # tests + HTML coverage report
```

### Lint & format

```bash
make lint            # ruff linter
make format          # black formatter
make format-check    # check without modifying
```

### Clean build artefacts

```bash
make clean
```

---

## Models

| Component | Default model |
|---|---|
| Embeddings | `sentence-transformers/all-MiniLM-L6-v2` (384-dim) |
| LLM | `meta-llama/Llama-3.2-3B-Instruct` via HF Inference API |

Both can be overridden by passing different `model_name` / `model_id` arguments to `get_embeddings()` and `get_llm()`.

---

## Requirements

- Python 3.11+
- A [HuggingFace](https://huggingface.co) account with API token
- A [Pinecone](https://www.pinecone.io) account with API key

---

## License

MIT